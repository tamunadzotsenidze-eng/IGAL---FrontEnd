#!/usr/bin/env python
"""
Comprehensive UAT Testing for IGAL Legal Assistant
Tests 10+ queries and validates:
1. Correct clauses/articles are retrieved
2. Answers are accurate and correspond to the clauses
3. Logic is sound and concrete
"""
import os
import sys
import django
import re
import json
from typing import Dict, List, Tuple

# Setup Django
sys.path.insert(0, '/Users/tiko/Desktop/IGAL/backend')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')
django.setup()

from rag.smart_retriever import get_smart_retriever
from rag.chat_integration import get_rag_integration
from rag.llm_intent_analyzer import get_llm_intent_analyzer

# UAT Test Questions (from user)
UAT_QUESTIONS = [
    "·É†·Éù·Éí·Éù·É† ·Éí·Éê·Éú·Éò·É°·Éê·Éñ·É¶·Éï·É†·Éî·Éë·Éê ·É§·Éò·Éñ·Éò·Éô·É£·É†·Éò ·Éû·Éò·É†·Éò·É° ·É†·Éî·Éñ·Éò·Éì·Éî·Éú·É¢·Éù·Éë·Éê ·É°·Éê·É•·Éê·É†·Éó·Éï·Éî·Éö·Éù·É®·Éò ·Éì·Éê ·É†·Éù·Éí·Éù·É†·Éò·Éê ·Éõ·Éê·É°·Éñ·Éî ·É°·Éê·Éí·Éê·Éì·Éê·É°·Éê·ÉÆ·Éê·Éì·Éù ·Éï·Éê·Éö·Éì·Éî·Éë·É£·Éö·Éî·Éë·Éî·Éë·Éò?",
    "·É†·Éê ·Éû·Éò·É†·Éù·Éë·Éò·Éó ·Éí·Éê·Éó·Éê·Éï·Éò·É°·É£·É§·Éö·Éì·Éî·Éë·Éê ·Éõ·Éê·É¶·Éê·Éö·Éò ·Éõ·Éó·Éò·É° ·É°·É¢·Éê·É¢·É£·É°·Éò·É° ·Éõ·É•·Éù·Éú·Éî ·Éû·Éò·É†·Éò ·É°·Éê·É®·Éî·Éõ·Éù·É°·Éê·Éï·Éö·Éù ·Éí·Éê·Éì·Éê·É°·Éê·ÉÆ·Éê·Éì·Éò·É°·Éí·Éê·Éú?",
    "·É†·Éê ·É¨·Éî·É°·Éò·Éó ·Éí·Éê·Éú·Éò·É°·Éê·Éñ·É¶·Éï·É†·Éî·Éë·Éê ·Éõ·Éù·Éí·Éî·Éë·Éò·É° ·Éí·Éê·Éì·Éê·É°·Éê·ÉÆ·Éê·Éì·Éò·É° ·Éù·Éë·Éò·Éî·É•·É¢·Éò ·Éò·É£·É†·Éò·Éì·Éò·É£·Éö·Éò ·Éû·Éò·É†·Éî·Éë·Éò·É°·Éó·Éï·Éò·É°?",
    "·É†·Éù·Éí·Éù·É†·Éò·Éê ·Éì·Éê·Éõ·Éê·É¢·Éî·Éë·É£·Éö·Éò ·É¶·Éò·É†·Éî·Éë·É£·Éö·Éî·Éë·Éò·É° ·Éí·Éê·Éì·Éê·É°·Éê·ÉÆ·Éê·Éì·Éò·É° (·Éì·É¶·Éí) ·Éí·Éê·Éì·Éê·ÉÆ·Éì·Éò·É° ·Éï·Éê·Éö·Éì·Éî·Éë·É£·Éö·Éî·Éë·Éò·É° ·É¨·Éê·É†·Éõ·Éù·É®·Éù·Éë·Éò·É° ·Éõ·Éù·Éõ·Éî·Éú·É¢·Éò?",
    "·É†·Éê ·É®·Éî·Éõ·Éó·ÉÆ·Éï·Éî·Éï·Éê·É®·Éò ·Éê·É†·Éò·É° ·É®·Éî·É°·Éê·É´·Éö·Éî·Éë·Éî·Éö·Éò ·Éí·Éê·Éì·Éê·É°·Éê·ÉÆ·Éê·Éì·Éò·É° ·ÉÆ·Éê·Éú·Éì·Éê·Éñ·Éõ·É£·Éö·Éù·Éë·Éò·É° ·Éï·Éê·Éì·Éò·É° ·Éí·Éê·Éí·É†·É´·Éî·Éö·Éî·Éë·Éê?",
    "·É†·Éù·Éí·Éù·É†·Éò·Éê ·É•·Éù·Éú·Éî·Éë·Éò·É° ·Éí·Éê·Éì·Éê·É°·Éê·ÉÆ·Éê·Éì·Éò·É° ·Éí·Éê·Éì·Éê·ÉÆ·Éì·Éò·É° ·Éï·Éê·Éö·Éì·Éî·Éë·É£·Éö·Éî·Éë·Éê ·Éì·Éê ·Éï·Éê·Éö·Éì·Éî·Éë·É£·Éö·Éò ·É°·É£·Éë·Éò·Éî·É•·É¢·Éî·Éë·Éò?",
    "·É†·Éù·Éí·Éù·É†·Éò·Éê ·É°·Éê·É®·Éî·Éõ·Éù·É°·Éê·Éï·Éö·Éù·É° ·Éí·Éê·Éì·Éê·É°·Éê·ÉÆ·Éê·Éì·Éò·É° ·Éí·Éê·Éì·Éê·ÉÆ·Éì·Éò·É° ·Éï·Éê·Éö·Éì·Éî·Éë·É£·Éö·Éî·Éë·Éê ·Éì·Éê ·É†·Éê·Éõ·Éì·Éî·Éú·Éò ·Éû·É†·Éù·É™·Éî·Éú·É¢·Éò·Éó ·Éí·Éê·Éú·Éò·É°·Éê·Éñ·É¶·Éï·É†·Éî·Éë·Éê?",
    "·É†·Éê ·É®·Éî·Éõ·Éó·ÉÆ·Éï·Éî·Éï·Éê·É®·Éò ·Éò·Éó·Éï·Éö·Éî·Éë·Éê ·Éï·Éê·Éö·Éò ·É£·Éò·Éõ·Éî·Éì·Éù ·Éï·Éê·Éö·Éê·Éì ·Éì·Éê ·É†·Éù·Éí·Éù·É† ·Éí·Éê·Éú·Éó·Éê·Éï·Éò·É°·É£·É§·Éö·Éì·Éî·Éë·Éê ·Éí·Éê·Éì·Éê·Éõ·ÉÆ·Éì·Éî·Éö·Éò ·Éì·É¶·Éí-·É°·Éí·Éê·Éú?",
    "·É†·Éù·Éí·Éù·É†·Éò·Éê ·É°·Éê·Éí·Éê·Éì·Éê·É°·Éê·ÉÆ·Éê·Éì·Éù ·É®·Éî·Éó·Éê·Éú·ÉÆ·Éõ·Éî·Éë·Éò·É° ·É°·Éê·Éõ·Éê·É†·Éó·Éö·Éî·Éë·É†·Éò·Éï·Éò ·É®·Éî·Éì·Éî·Éí·Éî·Éë·Éò?",
    "·É†·Éê ·Éû·Éò·É†·Éù·Éë·Éî·Éë·Éò·Éó ·É®·Éî·É°·Éê·É´·Éö·Éî·Éë·Éî·Éö·Éò·Éê ·É†·Éî·Éñ·Éò·Éì·Éî·Éú·É¢·Éò ·Éô·Éù·Éõ·Éû·Éê·Éú·Éò·Éò·É° ·Éõ·Éò·Éî·É† ·Éê·É†·Éê·É†·Éî·Éñ·Éò·Éì·Éî·Éú·É¢·Éò·É°·Éó·Éï·Éò·É° ·Éì·Éò·Éï·Éò·Éì·Éî·Éú·Éì·Éò·É°, ·É†·Éù·Éò·Éê·Éö·É¢·Éò·É° ·Éê·Éú ·Éû·É†·Éù·É™·Éî·Éú·É¢·Éò·É° ·Éí·Éê·Éì·Éê·ÉÆ·Éì·Éê ·Éì·Éê·Éë·Éî·Éí·É†·Éò·Éö·Éò ·É®·Éî·Éõ·É™·Éò·É†·Éî·Éë·É£·Éö·Éò ·Éí·Éê·Éú·Éê·Éô·Éï·Éî·Éó·Éò·Éó?",
]


def extract_article_numbers(text: str) -> List[str]:
    """Extract article numbers from Georgian text"""
    patterns = [
        r'(\d+)-·Éî\s+·Éõ·É£·ÉÆ·Éö',        # "81-·Éî ·Éõ·É£·ÉÆ·Éö·Éò"
        r'·Éõ·É£·ÉÆ·Éö·Éò\s+(\d+)',          # "·Éõ·É£·ÉÆ·Éö·Éò 81"
        r'·Éõ·É£·ÉÆ·Éö·Éò·É°\s+(\d+)',         # "·Éõ·É£·ÉÆ·Éö·Éò·É° 81"
        r'(\d+)\s+·Éõ·É£·ÉÆ·Éö·Éò',          # "81 ·Éõ·É£·ÉÆ·Éö·Éò"
        r'·Éõ·É£·ÉÆ·Éö(?:·Éò|·Éò·É°)?\s*‚Ññ\s*(\d+)',  # "·Éõ·É£·ÉÆ·Éö·Éò ‚Ññ81"
        r'‚Ññ\s*(\d+)\s+·Éõ·É£·ÉÆ·Éö',       # "‚Ññ81 ·Éõ·É£·ÉÆ·Éö·Éò"
    ]

    articles = []
    for pattern in patterns:
        matches = re.findall(pattern, text, re.UNICODE)
        articles.extend(matches)

    # Remove duplicates and sort
    return sorted(set(articles), key=lambda x: int(x) if x.isdigit() else 0)


def test_single_query(query: str, chat_integration) -> Dict:
    """
    Test a single query and return results

    Returns:
        Dict with:
        - query: Original query
        - answer: LLM answer
        - cited_articles: Article numbers mentioned in answer
        - retrieved_articles: Article numbers in retrieved context
        - retrieval_time_ms: Retrieval time
        - confidence: Retrieval confidence
        - layers_used: Which retrieval layers were used
    """
    print(f"\n{'='*100}")
    print(f"QUERY: {query}")
    print(f"{'='*100}")

    # Get answer from chat integration
    result = chat_integration.chat(
        user_message=query,
        conversation_history=[],
        session_id="uat_test"
    )

    answer = result.get('answer', '')
    metadata = result.get('metadata', {})
    retrieval_metadata = metadata.get('retrieval', {})

    # Extract articles mentioned in answer
    cited_articles = extract_article_numbers(answer)

    # Extract articles from retrieved context
    contexts = retrieval_metadata.get('contexts', [])
    retrieved_articles = []
    for ctx in contexts:
        article_num = ctx.get('clause') or ctx.get('article_number')
        if article_num:
            retrieved_articles.append(str(article_num))
    retrieved_articles = sorted(set(retrieved_articles), key=lambda x: int(x) if x.isdigit() else 0)

    # Print results
    print(f"\nüìä RETRIEVAL INFO:")
    print(f"   - Retrieved Articles: {retrieved_articles}")
    print(f"   - Confidence: {retrieval_metadata.get('confidence', 0):.2f}")
    print(f"   - Layers Used: {retrieval_metadata.get('layers_used', [])}")
    print(f"   - Time: {retrieval_metadata.get('total_time_ms', 0):.0f}ms")

    print(f"\nüí¨ ANSWER:")
    print(f"{answer}")

    print(f"\nüìã CITED ARTICLES IN ANSWER: {cited_articles}")

    # Check if cited articles match retrieved articles
    hallucinations = [art for art in cited_articles if art not in retrieved_articles]
    if hallucinations:
        print(f"\n‚ö†Ô∏è  WARNING: Hallucinated articles: {hallucinations}")
        print(f"   (These were cited but not in retrieved context)")
    else:
        print(f"\n‚úÖ All cited articles are in retrieved context")

    # Show retrieved context details
    print(f"\nüìö RETRIEVED CONTEXT DETAILS:")
    for i, ctx in enumerate(contexts[:3], 1):
        article_num = ctx.get('clause') or ctx.get('article_number')
        article_title = ctx.get('clause_name') or ctx.get('article_title', '')
        similarity = ctx.get('similarity', 0)
        print(f"\n   [{i}] Article {article_num}: {article_title}")
        print(f"       Similarity: {similarity:.3f}")
        print(f"       Text preview: {ctx.get('text', '')[:150]}...")

    return {
        'query': query,
        'answer': answer,
        'cited_articles': cited_articles,
        'retrieved_articles': retrieved_articles,
        'hallucinations': hallucinations,
        'retrieval_time_ms': retrieval_metadata.get('total_time_ms', 0),
        'confidence': retrieval_metadata.get('confidence', 0),
        'layers_used': retrieval_metadata.get('layers_used', []),
        'contexts': contexts[:3]  # Top 3 contexts
    }


def run_uat_tests():
    """Run all UAT tests and generate report"""
    print("\n" + "="*100)
    print("üß™ IGAL LEGAL ASSISTANT - COMPREHENSIVE UAT TESTING")
    print("="*100)
    print(f"\nTesting {len(UAT_QUESTIONS)} queries...")
    print("\nAcceptance Criteria:")
    print("  ‚úÖ Gets the right articles/clauses")
    print("  ‚úÖ Talks about the right context")
    print("  ‚úÖ Is concrete and logical")
    print("  ‚úÖ No hallucinated citations")

    # Initialize chat integration
    chat_integration = get_rag_integration()

    # Run tests
    results = []
    for i, query in enumerate(UAT_QUESTIONS, 1):
        print(f"\n\n{'#'*100}")
        print(f"TEST {i}/{len(UAT_QUESTIONS)}")
        print(f"{'#'*100}")

        result = test_single_query(query, chat_integration)
        results.append(result)

    # Generate summary report
    print("\n\n" + "="*100)
    print("üìä UAT SUMMARY REPORT")
    print("="*100)

    total_tests = len(results)
    tests_with_hallucinations = sum(1 for r in results if r['hallucinations'])
    avg_retrieval_time = sum(r['retrieval_time_ms'] for r in results) / total_tests
    avg_confidence = sum(r['confidence'] for r in results) / total_tests

    print(f"\nüìà Overall Statistics:")
    print(f"   - Total Tests: {total_tests}")
    print(f"   - Tests with Hallucinations: {tests_with_hallucinations}")
    print(f"   - Tests with Accurate Citations: {total_tests - tests_with_hallucinations}")
    print(f"   - Average Retrieval Time: {avg_retrieval_time:.0f}ms")
    print(f"   - Average Confidence: {avg_confidence:.2f}")

    print(f"\n\nüìã Test Results Summary:")
    print(f"{'='*100}")

    for i, result in enumerate(results, 1):
        status = "‚úÖ PASS" if not result['hallucinations'] else "‚ö†Ô∏è  WARN"
        print(f"\n{i}. {status}")
        print(f"   Query: {result['query'][:70]}...")
        print(f"   Retrieved: {result['retrieved_articles']}")
        print(f"   Cited: {result['cited_articles']}")
        if result['hallucinations']:
            print(f"   ‚ö†Ô∏è  Hallucinated: {result['hallucinations']}")
        print(f"   Confidence: {result['confidence']:.2f}, Time: {result['retrieval_time_ms']:.0f}ms")

    # Final verdict
    print(f"\n\n{'='*100}")
    if tests_with_hallucinations == 0:
        print("‚úÖ ALL TESTS PASSED - No hallucinations detected!")
        print("   System is providing accurate citations.")
    else:
        print(f"‚ö†Ô∏è  {tests_with_hallucinations}/{total_tests} tests had hallucinations")
        print("   Review the warnings above for details.")
    print(f"{'='*100}\n")

    return results


if __name__ == '__main__':
    run_uat_tests()
